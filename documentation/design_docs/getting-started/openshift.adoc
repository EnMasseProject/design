[[enmasse-on-openshift]]
= EnMasse on OpenShift

This guide will walk through the process of setting up EnMasse on
OpenShift with clients for sending and receiving messages.

[[preqrequisites]]
== Prerequisites

In this guide, you need the OpenShift client tools. You can download the
https://github.com/openshift/origin/releases[OpenShift Origin] client
for this guide. EnMasse will work with the latest stable release.

If you have an OpenShift instance running already, you can start setting
up EnMasse. If not, follow
https://github.com/openshift/origin/blob/master/docs/cluster_up_down.md[this
guide] for setting up a local developer instance of OpenShift.

[[setting-up-enmasse]]
== Setting up EnMasse

[[installing]]
=== Installing

Download one of the releases from
https://github.com/EnMasseProject/enmasse/releases and unpack it. Once
unpacked, you can either deploy EnMasse using an automated script or
follow the below steps.

[[deploying-enmasse-automatically]]
==== Deploying EnMasse automatically

The deployment script simplifies the process of deploying the enmasse
cluster. You can invoke it with `-h` to get a list of options. To
deploy:

....
./deploy-openshift.sh -m "https://localhost:8443" -n enmasse
....

This will create the deployments required for running EnMasse. Starting
up EnMasse will take a while, usually depending on how fast it is able
to download the docker images for the various components. In the
meantime, you can start to create your address configuration.

[[deploying-enmasse-manually]]

==== Deploying EnMasse manually

Login as developer:

....
oc login -u developer  https://localhost:8443
....

Create new project enmasse:

....
oc new-project enmasse
....

Create service account for address controller:

....
oc create sa enmasse-service-account -n enmasse
....

Add permissions for viewing OpenShift resources to default user:

....
oc policy add-role-to-user view system:serviceaccount:enmasse:default
....

Add permissions for editing OpenShift resources to EnMasse service account:

....
oc policy add-role-to-user edit system:serviceaccount:enmasse:enmasse-service-account
....

Create self-signed certificate:

....
openssl req -new -x509 -batch -nodes -days 11000 -subj "/O=io.enmasse/CN=enmasse" -out /tmp/enmasse-deploy.CAQZri/ca.crt -keyout /tmp/enmasse-deploy.CAQZri/ca.key
....

Create enmasse-ca TLS secret:

....
cat <<EOF | oc create -n enmasse -f -
{
    "apiVersion": "v1",
    "kind": "Secret",
    "metadata": {
        "name": "enmasse-ca"
    },
    "type": "kubernetes.io/tls",
    "data": {
        "tls.key": "$(base64 -w 0 /tmp/enmasse-deploy.CAQZri/ca.key)",
        "tls.crt": "$(base64 -w 0 /tmp/enmasse-deploy.CAQZri/ca.crt)"
    }
}
EOF
....

Create certificate signing request for address-controller.enmasse.svc.cluster.local:

....
openssl req -new -batch -nodes -keyout /tmp/enmasse-deploy.CAQZri/address-controller.enmasse.svc.cluster.local.key -subj "/O=io.enmasse/CN=address-controller.enmasse.svc.cluster.local" -out /tmp/enmasse-deploy.CAQZri/address-controller.enmasse.svc.cluster.local.csr
....

Sign address-controller certificate with CA key:

....
openssl x509 -req -days 11000 -in /tmp/enmasse-deploy.CAQZri/address-controller.enmasse.svc.cluster.local.csr -CA /tmp/enmasse-deploy.CAQZri/ca.crt -CAkey /tmp/enmasse-deploy.CAQZri/ca.key -CAcreateserial -out /tmp/enmasse-deploy.CAQZri/address-controller.enmasse.svc.cluster.local.crt
....

Create address-controller-cert TLS secret:

....
cat <<EOF | oc create -n enmasse -f -
{
    "apiVersion": "v1",
    "kind": "Secret",
    "metadata": {
        "name": "address-controller-cert"
    },
    "type": "kubernetes.io/tls",
    "data": {
        "tls.key": "$(base64 -w 0 /tmp/enmasse-deploy.CAQZri/address-controller.enmasse.svc.cluster.local.key)",
        "tls.crt": "$(base64 -w 0 /tmp/enmasse-deploy.CAQZri/address-controller.enmasse.svc.cluster.local.crt)"
    }
}
EOF
....

Create self-signed certificate for none-authservice.enmasse.svc.cluster.local:

....
openssl req -new -x509 -batch -nodes -days 11000 -out /tmp/enmasse-deploy.CAQZri/none-authservice.enmasse.svc.cluster.local.crt -keyout /tmp/enmasse-deploy.CAQZri/none-authservice.enmasse.svc.cluster.local.key -subj "/O=io.enmasse/CN=none-authservice.enmasse.svc.cluster.local"
....

Create none-authservice-cert TLS secret:

....
cat <<EOF | oc create -n enmasse -f -
{
    "apiVersion": "v1",
    "kind": "Secret",
    "metadata": {
        "name": "none-authservice-cert"
    },
    "type": "kubernetes.io/tls",
    "data": {
        "tls.key": "$(base64 -w 0 /tmp/enmasse-deploy.CAQZri/none-authservice.enmasse.svc.cluster.local.key)",
        "tls.crt": "$(base64 -w 0 /tmp/enmasse-deploy.CAQZri/none-authservice.enmasse.svc.cluster.local.crt)"
    }
}
EOF
....

Create none authservice:

....
oc process -f ./openshift/addons/none-authservice.yaml | oc create -n enmasse -f -
....

Instantiate EnMasse template:

....
oc process -f ./openshift/enmasse.yaml  | oc create -n enmasse -f -
....



[[configuring-addresses]]
=== Configuring addresses

EnMasse is configured with a set of addresses that you can use for
messages. Currently, EnMasse supports 4 different address types:

* Brokered queues
* Brokered topics (pub/sub)
* Direct anycast addresses
* Direct broadcast addresses

See the link:../address-model/model.adoc[address model] for details.
EnMasse also comes with a console that you can use for managing
addresses. You can get the console URL by running

....
echo "http://$(oc get route -o jsonpath='{.spec.host}' console)"
....

You can also deploy the addressing config using the address controller
API. See link:../address-model/resource-definitions.adoc[resource
definitions] for details on the resources consumed by the API. Here is
an example config with all 4 variants that you can save to
`addresses.json`:

....
{
  "apiVersion": "enmasse.io/v1",
  "kind": "AddressList",
  "items": [
    {
      "metadata": {
        "name": "myqueue"
      },
      "spec": {
        "type": "queue"
      }
    },
    {
      "metadata": {
        "name": "mytopic"
      },
      "spec": {
        "type": "topic"
      }
    },
    {
      "metadata": {
        "name": "myanycast"
      },
      "spec": {
        "type": "anycast"
      }
    },
    {
      "metadata": {
        "name": "mymulticast"
      },
      "spec": {
        "type": "multicast"
      }
    }
  ]
}
....

To deploy this configuration, you must currently use a http client like
curl:

....
curl -X POST -H "content-type: application/json" --data-binary @addresses.json http://$(oc get route -o jsonpath='{.spec.host}' restapi)/v1/addresses/default
....

This will connect to the address controller REST API to deploy the
address config.

[[sending-and-receiving-messages]]
=== Sending and receiving messages

[[amqp]]
==== AMQP

For sending and receiving messages, have a look at an example python
http://qpid.apache.org/releases/qpid-proton-0.15.0/proton/python/examples/simple_send.py.html[sender]
and
http://qpid.apache.org/releases/qpid-proton-0.15.0/proton/python/examples/simple_recv.py.html[receiver].

To send and receive messages, you can either connect using the local
service IP or the external route. To connect a client using the local
service IP:

....
./simple_recv.py -a "amqp://$(oc get service -o jsonpath='{.spec.clusterIP}' messaging)/anycast" -m 10
....

This will block until it has received 10 messages. To start the sender:

....
./simple_send.py -a "amqp://$(oc get service -o jsonpath='{.spec.clusterIP}' messaging)/anycast" -m 10
....

You can use the client with the 'myqueue' and 'broadcast' and 'mytopic'
addresses as well.

To use the external routes for sending and receiving messages:

....
./simple_send.py -a "amqps://$(oc get route -o jsonpath='{.spec.host}' messaging):443/anycast" -m 10
....

[[mqtt]]
==== MQTT

For sending and receiving messages, the `mosquitto` clients are the simpler way to go. These clients can be used either against the local service IP or the external route. To connect using the local service IP:

In order to subscribe to a topic (i.e. `mytopic` from the previous addresses configuration), the `mosquitto_sub` can be used in the following way :

....
mosquitto_sub -h $(oc get service -o jsonpath='{.spec.clusterIP}' mqtt) -t mytopic -q 1
....

Then the subscriber is waiting for messages published on that topic. To start the publisher, the `mosquitto_pub` can be used in the following way :

....
mosquitto_pub -h $(oc get service -o jsonpath='{.spec.clusterIP}' mqtt) -t mytopic -q 1 -m "Hello EnMasse"
....

The the publisher publishes the message and disconnects from EnMasse.
The message is received by the previous connected subscriber.

For sending and receiving messages using the external route, have a look at an example python link:tls_mqtt_send.py[sender] and link:tls_mqtt_recv.py[receiver].

In order to subscribe to a topic (i.e. `mytopic` from the previous addresses configuration), the receiver client can be used in the following way :

....
./tls_mqtt_recv.py -c "$(oc get route -o jsonpath='{.spec.host}' mqtt)" -p 443 -t mytopic -q 1 -s ./server-cert.pem
....

Then the subscriber is waiting for messages published on that topic. To start the publisher, the sender client can be used in the following way :

....
./tls_mqtt_send.py -c "$(oc get route -o jsonpath='{.spec.host}' mqtt)" -p 443 -t mytopic -q 1 -s ./server-cert.pem -m "Hello EnMasse"
....

The the publisher publishes the message and disconnects from EnMasse.
The message is received by the previous connected subscriber.

[[conclusion]]
== Conclusion

We have seen how to setup EnMasse, and how to communicate with it using
AMQP and MQTT clients.
