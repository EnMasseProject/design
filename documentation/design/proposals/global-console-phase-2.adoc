
:toc:
:toclevels: 4

== Global Console Phase 2.

=== Introduction

Currently, the Console in EnMasse actually comprises two separate web-applications that are hyperlinked together.  These are
known as the Global Console (which allows create/read/update/delete of address spaces), and the Address Space Console
which allows the addresses within an address space to be managed and the connections to the address space to be seen.
In addition the Address Space Console exposed address and connection level statistics.

For this phase, the reposibilities of for address management, address metrics, connection view and connection metrics
will be transfered to Global Console.  This will allow the Address Space Console to be retired and the agent relieved of
responsibilities for serving the Address Space Console application.

The deployment of the Console will be controlled by the consoleservice CR.  This work will make it possible for EnMasse
to be used without the Console, if desired.

== High Level

There will be a new *console-graphql* component.  This will be deployed to the console pod and will be fronted by ouath-proxy.
The console-httpd sidecar will be retired.

The *console-graphql* component will present GraphQL API allowing the view/maintainence of address spaces, addresss,
and connections by the UI.  The model presented object model presented by the EnMasse GraphQL schema will be a composite
one that provides access to the resource and its metrics through a single query interface.  Mutations will permit the
create/patch/delete of address spaces and addresses, the closure of connections and purge of addresses.

The console-graphql internally will build a *cache* of address-spaces, addresses and connections, links and metrics. 

* address-spaces and addresses will be read from the Kubernetes API (utilising watches of the resources).
* connection and link information will be gathered from the agents of addressspaces themselves.
* metrics will also be scraped *directly* from the agents. 

For read operations, console-graphql will use a service acccount with *list* permission for address spaces and addresses
in order to build a global view.  It will be a responsibility of component to filter the user's view so that he can see 
only those objects to which he has permission.  It will use SelfSubjectAccessReview in order to do this.  The
SelfSubjectAccessReview responses will be cached for a short time, to save load on the server.

For write operations, console-graphql will propagate the user's bearer token made available by oauth-proxy.

Authentication will remain unchanged i.e. oauth-proxy retains the responsibility.


== Components

=== console-graphql

Console-graphql will replace the HTTP sidecar.  

It will have the following responsibilities:

* present a GraphQL interface
** for queries - exposing address-spaces, addresses, connection together will link and metric information.
** for mutations - allow creation/patch/delete of address-space/address, connection close, address purge.
* populate cache with
** address-space and address (from Kubernetes API)
** connections and links (from the addressspaces' agents)
** metrics (from the addressspaces' agents)

==== GraphQL queries

Root queries.

==== GraphQL mutations

==== Cache

The console-graphql will maintain a cache of addressspapce/address/connection, link and metric infiormation.

====  Addressspaces/Address

Console-graphql will use a watch of on the addressspace and address to populate the model.

==== Connections and Link information.

In order to locate the agent endpoint, the console-server will populate a lookup map. It will do this by watching for agent services.  When an agent service appears, it will resolve its addressspace using the `infraUuid`.

It will connect to the agent, and periodically poll for connections and link information.  This information will be
added to the cache.

==== Metrics

=== agent

The Address Space Console and the server side support for the AMQP management interface is removed.

Agent acquires a responsibility for exposing connections to the addressspace over HTTP.  This endpoint will require authentication (bearer token).  For the authorisation check, it will perform a self subject review for a GET on the addresspace.  If the user has permission to view the addresses, they also have permission to view its connections.

The Agent will be changed to expose the additional metrics listed in the next section.  The existing metrics produced by 
agent will be maintained.   The Prometheus documentation [https://prometheus.io/docs/practices/naming/#labels](warns) against metrics whose labels may exhibit high cardinality.  The connection and address metrics depending on the messaging use-case
present this problem.  For this reason the metrics endpoint will disable these statistics by default.  This will avoid changes to the configuration for the existing EnMasse Monitoring .  For the inbuilt Prometheus, the connection and address metrics would be enabled.

A later development interation will add support for DELETE connection to allow a connection to be closed.  This will require the the user has update permission to the address space.

=== global console

The code that currently aggregates the addresssspace list from all namespaces can be replaced with use of the *all namespace list* feature.   The console will continue to manage the addressspace using the proxied kubernetes api. 

For addresses and connections, the pattern already established by addressspaces can be followed.  The fact that connections are not a kubernetes object will be hidden from the console.

It will the responsibility of the console to poll the statistics api to gather than metrics for the resource(s) that are being viewed.  There will be some common code produces that will simplify the marrying of the kubernetes result set to the statistics results.

The console must  torrerate to a metric it expects being absent from the result set.


=== console-owned prometheus instance

A Prometheus instance will be deployed with the console-server (side-car) whose responsibility is to scrape addressspace, address and connnection metrics from the each agent.  Agent instance will be discovered using `kubernetes_sd_configs` type configuration.

The prometheus documentation warns:

> CAUTION: Remember that every unique combination of key-value label pairs represents a new time series, which can dramatically increase the amount of data stored. Do not use labels to store dimensions with high cardinality (many different label values), such as user IDs, email addresses, or other unbounded sets of values.

This could present a problem for some of the connection and address metrics for use-cases involving large numbers of connections or queues.  Some common messaging anti-patterns (connection per message) may explode the number of connections gathered.    

To counter this, the Prometheus instance will be configured with short rentention policy and a small retention size.  In addition the prometheus configuration will be exposed so it can altered without a code change just in case the metrics scraping proved problematic for a use-case.

== Metrics

=== AddressSpaces

* enmasse_addresses(labels:<addressspace>)  (instantaneous value, number of addresses currently defined) 
* enmasse_connections(labels:<addressspace>) (instantaneous value, number of connections currently made) 
* enmasse_messages_in_total(labels:<addressspace>)  (monotonically increasing cumulative metric)
* enmasse_messages_in_total(labels:<addressspace>) (monotonically increasing cumulative metric)

=== Addresses

* enmasse_messages_in_total(labels:<addressspace>,<address>)  (monotonically increasing cumulative metric)
* enmasse_messages_out_total(labels:<addressspace>,<address>)  (monotonically increasing cumulative metric)
* enmasse_messages_stored(labels:<addressspace>,<address>) (instantaneous value)
* enmasse_senders(labels:<addressspace>,<address>) (instantaneous value)
* enmasse_receivers(labels:<addressspace>,<address>) (instantaneous value)
* enmasse_shards(labels:<addressspace>,<address>) (instantaneous value)  Do we really want this?


=== AddressDetails

(captures each sender/receiver attached to the address, capturing container id, role and the link name)
* enmasse_messages_in_total(labels:<addressspace>,<address>,<containerid>,<linkid>)  (monotonically increasing cumulative metric)
* enmasse_messages_out_total(labels:<addressspace>,<address>,<containerid>,<linkid>)  (monotonically increasing cumulative metric)
* enmasse_backlog(labels:<addressspace>,<address>,<containerid>,<linkid>)  (instantaneous value)

=== Connection

(captures each connection to the service: hostname:port, container id, protocol, secure)

* enmasse_messages_in_total(labels:<remote hostport>,<remote containerid>)  (monotonically increasing cumulative metric)
* enmasse_messages_out_total(labels:<remote hostport>,<remote containerid>)  (monotonically increasing cumulative metric)
* enmasse_senders(labels:<remote hostport>,<remote containerid>) (instantaneous value)
* enmasse_receivers(labels:<remote hostport>,<remote containerid>) (instantaneous value)

=== ConnectionDetails

(captures each sender/receiver attached of the connection,capturing role, link name, address)

foreach l in Deliveries, Rejected,Released, Modified,Presettled,Undelivered

* enmasse_link_stat(labels:<remote hostport>,<remote containerid>,<linkid>,<address>,l) (instantaneous value)


== Alternatives

=== Avoiding the need for a console-owned Prometheus

The design above requires a prometheus instance which would be co-locate with the console-server.

It is possible to avoid the need for this instance as follows.

The console-server would scrape the metrics from the discovered agent instances directly and build an internal cache of the metrics. The statistics API would operate against this cache.  In this approach we would not have the richness of the PromQL to compute statistics (rates etc), so would need an alternative mechanism for these metrics.   For the first development interation we opt for a simple configuration driven mechanism.  Unfortunately the PromQL library is not released separately and it does not appear to lend itself to re-use.


= Notes

https://www.robustperception.io/using-sample_limit-to-avoid-overload
https://promcon.io/2017-munich/slides/best-practices-and-beastly-pitfalls.pdf

"Unbounded label values will blow up Prometheus"
https://prometheus.io/docs/practices/naming/


CAUTION: Remember that every unique combination of key-value label pairs represents a new time series, which can dramatically increase the amount of data stored. Do not use labels to store dimensions with high cardinality (many different label values), such as user IDs, email addresses, or other unbounded sets of values.


https://stackoverflow.com/questions/46373442/how-dangerous-are-high-cardinality-labels-in-prometheus
https://prometheus.io/docs/practices/instrumentation/#do-not-overuse-labels



https://github.com/prometheus/prometheus/issues/3200

Storage retention

https://www.robustperception.io/configuring-prometheus-storage-retention






Pagination “Relay Cursor Connections Specification.” (borrows terms from Graph Theory)

https://blog.apollographql.com/explaining-graphql-connections-c48b7c3d6976



